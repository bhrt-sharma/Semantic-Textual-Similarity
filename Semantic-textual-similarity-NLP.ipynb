{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/nlpword2vecembeddingspretrained/glove.6B.50d.txt\n/kaggle/input/nlpword2vecembeddingspretrained/glove.6B.200d.txt\n/kaggle/input/nlpword2vecembeddingspretrained/GoogleNews-vectors-negative300.bin\n/kaggle/input/nlpword2vecembeddingspretrained/glove.6B.100d.txt\n/kaggle/input/nlpword2vecembeddingspretrained/glove.6B.300d.txt\n/kaggle/input/semantic-textual-similarity-dataset/SMT_734_sentance.txt\n/kaggle/input/semantic-textual-similarity-dataset/Microsoft_750_Captions.txt\n/kaggle/input/semantic-textual-similarity-dataset/SMT_734_score.txt\n/kaggle/input/semantic-textual-similarity-dataset/Microsoft_750_sentances.txt\n/kaggle/input/semantic-textual-similarity-dataset/Microsoft_750_score.txt\n/kaggle/input/semantic-textual-similarity-dataset/Microsoft_750_Captions_score.txt\n/kaggle/input/glove840b300dtxt/glove.840B.300d.txt\n/kaggle/input/freqqq/doc_frequencies.tsv\n/kaggle/input/freqqq/frequencies.tsv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_file = open(\"/kaggle/input/semantic-textual-similarity-dataset/Microsoft_750_Captions.txt\")\noutput_file = open(\"/kaggle/input/semantic-textual-similarity-dataset/Microsoft_750_Captions_score.txt\")","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sent_df=pd.read_csv(input_file, sep='\\t', engine='python')\nsim_df = pd.read_csv(output_file, sep='\\t', engine='python')\nmicro_df = pd.merge(sent_df,sim_df,left_index=True,right_index=True)","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"micro_df[:5]","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"                  A man is riding a bicycle.  \\\n0   A woman and man are dancing in the rain.   \n1                        Someone is drawing.   \n2  A man and a woman are kissing each other.   \n3               A woman is slicing an onion.   \n4                A person is peeling shrimp.   \n\n                        A man is riding a bike.  5.000  \n0          A man and woman are dancing in rain.    5.0  \n1                           Someone is dancing.    0.3  \n2  A man and a woman are talking to each other.    0.6  \n3                  A woman is cutting an onion.    4.2  \n4                 A person is preparing shrimp.    3.6  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A man is riding a bicycle.</th>\n      <th>A man is riding a bike.</th>\n      <th>5.000</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A woman and man are dancing in the rain.</td>\n      <td>A man and woman are dancing in rain.</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Someone is drawing.</td>\n      <td>Someone is dancing.</td>\n      <td>0.3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A man and a woman are kissing each other.</td>\n      <td>A man and a woman are talking to each other.</td>\n      <td>0.6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A woman is slicing an onion.</td>\n      <td>A woman is cutting an onion.</td>\n      <td>4.2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A person is peeling shrimp.</td>\n      <td>A person is preparing shrimp.</td>\n      <td>3.6</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"micro_df.rename(columns={'A man is riding a bicycle.':'sent_1',\n                        'A man is riding a bike.':'sent_2',\n                        '5.000':'sim'},\n               inplace=True)\n","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"micro_df","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"                                        sent_1  \\\n0     A woman and man are dancing in the rain.   \n1                          Someone is drawing.   \n2    A man and a woman are kissing each other.   \n3                 A woman is slicing an onion.   \n4                  A person is peeling shrimp.   \n..                                         ...   \n744              Two men are dancing together.   \n745           A woman is running on the beach.   \n746                 A man is reading an email.   \n747                  A man is straining pasta.   \n748                   Panda's play on a swing.   \n\n                                           sent_2  sim  \n0            A man and woman are dancing in rain.  5.0  \n1                             Someone is dancing.  0.3  \n2    A man and a woman are talking to each other.  0.6  \n3                    A woman is cutting an onion.  4.2  \n4                   A person is preparing shrimp.  3.6  \n..                                            ...  ...  \n744                       A woman opens a closet.  0.0  \n745                  A dog is swimming in a pool.  0.0  \n746                    A person opening a banana.  0.0  \n747                   A man plays a wooden flute.  0.0  \n748                      A man is playing guitar.  0.8  \n\n[749 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sent_1</th>\n      <th>sent_2</th>\n      <th>sim</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A woman and man are dancing in the rain.</td>\n      <td>A man and woman are dancing in rain.</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Someone is drawing.</td>\n      <td>Someone is dancing.</td>\n      <td>0.3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A man and a woman are kissing each other.</td>\n      <td>A man and a woman are talking to each other.</td>\n      <td>0.6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A woman is slicing an onion.</td>\n      <td>A woman is cutting an onion.</td>\n      <td>4.2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A person is peeling shrimp.</td>\n      <td>A person is preparing shrimp.</td>\n      <td>3.6</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>744</th>\n      <td>Two men are dancing together.</td>\n      <td>A woman opens a closet.</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>745</th>\n      <td>A woman is running on the beach.</td>\n      <td>A dog is swimming in a pool.</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>746</th>\n      <td>A man is reading an email.</td>\n      <td>A person opening a banana.</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>747</th>\n      <td>A man is straining pasta.</td>\n      <td>A man plays a wooden flute.</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>748</th>\n      <td>Panda's play on a swing.</td>\n      <td>A man is playing guitar.</td>\n      <td>0.8</td>\n    </tr>\n  </tbody>\n</table>\n<p>749 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import scipy\nimport math\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# def load_sts_dataset(filename):\n#     # Loads a subset of the STS dataset into a DataFrame. In particular both\n#     # sentences and their human rated similarity score.\n#     sent_pairs = []\n#     with tf.io.gfile.GFile(filename, \"r\") as f:\n#         for line in f:\n#             ts = line.strip().split(\"\\t\")\n#             sent_pairs.append((ts[5], ts[6], float(ts[4])))\n#     return pd.DataFrame(sent_pairs, columns=[\"sent_1\", \"sent_2\", \"sim\"])\n\n\n# def download_and_load_sts_data():\n#     sts_dataset = tf.keras.utils.get_file(\n#         fname=\"Stsbenchmark.tar.gz\",\n#         origin=\"http://ixa2.si.ehu.es/stswiki/images/4/48/Stsbenchmark.tar.gz\",\n#         extract=True)\n\n#     sts_dev = load_sts_dataset(os.path.join(os.path.dirname(sts_dataset), \"stsbenchmark\", \"sts-dev.csv\"))\n#     sts_test = load_sts_dataset(os.path.join(os.path.dirname(sts_dataset), \"stsbenchmark\", \"sts-test.csv\"))\n\n#     return sts_dev, sts_test\n\n# sts_dev, sts_test = download_and_load_sts_data()","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sts_test","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import requests\n\n# def download_sick(f): \n\n#     response = requests.get(f).text\n\n#     lines = response.split(\"\\n\")[1:]\n#     lines = [l.split(\"\\t\") for l in lines if len(l) > 0]\n#     lines = [l for l in lines if len(l) == 5]\n\n#     df = pd.DataFrame(lines, columns=[\"idx\", \"sent_1\", \"sent_2\", \"sim\", \"label\"])\n#     df['sim'] = pd.to_numeric(df['sim'])\n#     return df\n    \n# sick_train = download_sick(\"https://raw.githubusercontent.com/alvations/stasis/master/SICK-data/SICK_train.txt\")\n# sick_dev = download_sick(\"https://raw.githubusercontent.com/alvations/stasis/master/SICK-data/SICK_trial.txt\")\n# sick_test = download_sick(\"https://raw.githubusercontent.com/alvations/stasis/master/SICK-data/SICK_test_annotated.txt\")\n# sick_all = sick_train.append(sick_test).append(sick_dev)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sick_all[:5]","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sick_all['label'].value_counts()","execution_count":11,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preparation"},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\n\nSTOP = set(nltk.corpus.stopwords.words(\"english\"))\n\nclass Sentence:\n    \n    def __init__(self, sentence):\n        self.raw = sentence\n        normalized_sentence = sentence.replace(\"‘\", \"'\").replace(\"’\", \"'\")\n        self.tokens = [t.lower() for t in nltk.word_tokenize(normalized_sentence)]\n        self.tokens_without_stop = [t for t in self.tokens if t not in STOP]","execution_count":12,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, we're going to use the popular Gensim library to load two sets of widely used pre-trained word embeddings: word2vec and GloVe."},{"metadata":{"trusted":true},"cell_type":"code","source":"import gensim\n\nfrom gensim.models import Word2Vec\nfrom gensim.scripts.glove2word2vec import glove2word2vec\n\nPATH_TO_WORD2VEC = os.path.expanduser(\"/kaggle/input/nlpword2vecembeddingspretrained/GoogleNews-vectors-negative300.bin\")\nPATH_TO_GLOVE = os.path.expanduser(\"/kaggle/input/glove840b300dtxt/glove.840B.300d.txt\")\n\nword2vec = gensim.models.KeyedVectors.load_word2vec_format(PATH_TO_WORD2VEC, binary=True)","execution_count":13,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To load Glove, we have to convert the downloaded GloVe file to word2vec format and then load the embeddings into a Gensim model. \n\n**This will take some time.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# tmp_file = \"/kaggle/input/glove840b300dtxt/glove.840B.300d.txt\"\n# glove2word2vec(PATH_TO_GLOVE, tmp_file)\n# glove = gensim.models.KeyedVectors.load_word2vec_format(tmp_file)\n\n# glove = Word2Vec(sentences, size=300, window=5, min_count=3, workers=4)","execution_count":14,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally, in order to compute weighted averages of word embeddings later, we are going to load a file with word frequencies. These word frequencies have been collected from Wikipedia and saved in a tab-separated file."},{"metadata":{"trusted":true},"cell_type":"code","source":"import csv\n\n\nPATH_TO_FREQUENCIES_FILE = \"/kaggle/input/freqqq/doc_frequencies.tsv\"\nPATH_TO_DOC_FREQUENCIES_FILE = \"/kaggle/input/freqqq/frequencies.tsv\"\n\ndef read_tsv(f):\n    frequencies = {}\n    with open(f) as tsv:\n        tsv_reader = csv.reader(tsv, delimiter=\"\\t\")\n        for row in tsv_reader: \n            frequencies[row[0]] = int(row[1])\n        \n    return frequencies\n        \nfrequencies = read_tsv(PATH_TO_FREQUENCIES_FILE)\ndoc_frequencies = read_tsv(PATH_TO_DOC_FREQUENCIES_FILE)\ndoc_frequencies[\"NUM_DOCS\"] = 1288431","execution_count":15,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Similarity methods"},{"metadata":{},"cell_type":"markdown","source":"### Baseline"},{"metadata":{},"cell_type":"markdown","source":"As our baseline, we're going for the simplest way of computing sentence embeddings: just take the embeddings of the words in the sentence (minus the stopwords), and compute their average, weighted by the sentence frequency of each word.\n\nWe then use the cosine to calculate the similarity between two sentence embeddings."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics.pairwise import cosine_similarity\nfrom collections import Counter\nimport math\n\ndef run_avg_benchmark(sentences1, sentences2, model=None, use_stoplist=False, doc_freqs=None): \n\n    if doc_freqs is not None:\n        N = doc_freqs[\"NUM_DOCS\"]\n    \n    sims = []\n    for (sent1, sent2) in zip(sentences1, sentences2):\n    \n        tokens1 = sent1.tokens_without_stop if use_stoplist else sent1.tokens\n        tokens2 = sent2.tokens_without_stop if use_stoplist else sent2.tokens\n\n        tokens1 = [token for token in tokens1 if token in model]\n        tokens2 = [token for token in tokens2 if token in model]\n        \n        if len(tokens1) == 0 or len(tokens2) == 0:\n            sims.append(0)\n            continue\n        \n        tokfreqs1 = Counter(tokens1)\n        tokfreqs2 = Counter(tokens2)\n        \n        weights1 = [tokfreqs1[token] * math.log(N/(doc_freqs.get(token, 0)+1)) \n                    for token in tokfreqs1] if doc_freqs else None\n        weights2 = [tokfreqs2[token] * math.log(N/(doc_freqs.get(token, 0)+1)) \n                    for token in tokfreqs2] if doc_freqs else None\n                \n        embedding1 = np.average([model[token] for token in tokfreqs1], axis=0, weights=weights1).reshape(1, -1)\n        embedding2 = np.average([model[token] for token in tokfreqs2], axis=0, weights=weights2).reshape(1, -1)\n\n        sim = cosine_similarity(embedding1, embedding2)[0][0]\n        sims.append(sim)\n\n    return sims","execution_count":16,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Word Mover's Distance"},{"metadata":{},"cell_type":"markdown","source":"Word mover's distance is a popular alternative to the simple average embedding similarity. The Word Mover's Distance uses the word embeddings of the words in two texts to measure the minimum amount that the words in one text need to \"travel\" in semantic space to reach the words of the other text. Word mover's distance is available in the popular Gensim library."},{"metadata":{"trusted":true},"cell_type":"code","source":"def run_wmd_benchmark(sentences1, sentences2, model, use_stoplist=False):\n    \n    sims = []\n    for (sent1, sent2) in zip(sentences1, sentences2):\n    \n        tokens1 = sent1.tokens_without_stop if use_stoplist else sent1.tokens\n        tokens2 = sent2.tokens_without_stop if use_stoplist else sent2.tokens\n        \n        tokens1 = [token for token in tokens1 if token in model]\n        tokens2 = [token for token in tokens2 if token in model]\n        \n        if len(tokens1) == 0 or len(tokens2) == 0:\n            tokens1 = [token for token in sent1.tokens if token in model]\n            tokens2 = [token for token in sent2.tokens if token in model]\n            \n        sims.append(-model.wmdistance(tokens1, tokens2))\n        \n    return sims","execution_count":17,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Smooth Inverse Frequency"},{"metadata":{},"cell_type":"markdown","source":"Taking the average of the word embeddings in a sentence, like we did above, is a very crude method of computing sentence embeddings. Most importantly, this gives far too much weight to words that are quite irrelevant, semantically speaking. Smooth Inverse Frequency tries to solve this problem.\n\nTo compute SIF sentence embeddings, we first compute a weighted average of the token embeddings in the sentence. This procedure is very similar to the weighted average we used above, with the single difference that the word embeddings are weighted by a/a+p(w), where w is a parameter that is set to 0.001 by default, and p(w) is the estimated relative frequency of a word in a reference corpus.\n\nNext, we need to perform common component removal: we compute the principal component of the sentence embeddings we obtained above and subtract from them their projections on this first principal component. This corrects for the influence of high-frequency words that mostly have a syntactic or discourse function, such as \"just\", \"there\", \"but\", etc."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import TruncatedSVD\n\ndef remove_first_principal_component(X):\n    svd = TruncatedSVD(n_components=1, n_iter=7, random_state=0)\n    svd.fit(X)\n    pc = svd.components_\n    XX = X - X.dot(pc.transpose()) * pc\n    return XX\n\n\ndef run_sif_benchmark(sentences1, sentences2, model, freqs={}, use_stoplist=False, a=0.001): \n    total_freq = sum(freqs.values())\n    \n    embeddings = []\n    \n    # SIF requires us to first collect all sentence embeddings and then perform \n    # common component analysis.\n    for (sent1, sent2) in zip(sentences1, sentences2): \n        \n        tokens1 = sent1.tokens_without_stop if use_stoplist else sent1.tokens\n        tokens2 = sent2.tokens_without_stop if use_stoplist else sent2.tokens\n        \n        tokens1 = [token for token in tokens1 if token in model]\n        tokens2 = [token for token in tokens2 if token in model]\n        \n        weights1 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens1]\n        weights2 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens2]\n        \n        embedding1 = np.average([model[token] for token in tokens1], axis=0, weights=weights1)\n        embedding2 = np.average([model[token] for token in tokens2], axis=0, weights=weights2)\n        \n        embeddings.append(embedding1)\n        embeddings.append(embedding2)\n        \n    embeddings = remove_first_principal_component(np.array(embeddings))\n    sims = [cosine_similarity(embeddings[idx*2].reshape(1, -1), \n                              embeddings[idx*2+1].reshape(1, -1))[0][0] \n            for idx in range(int(len(embeddings)/2))]\n\n    return sims","execution_count":18,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The methods above share two important characteristics:\n\n- As simple bag-of-word methods, they do take not word order into account.\n- The word embeddings they use have been learned in an unsupervised manner.\n\n\nBoth these characteristics are potential downsides:\n\n- Since differences in word order can point to differences in meaning (compare the dog bites the man with the man bites the dog), we'd like our sentence embeddings to be sensitive to this variation.\n- Supervised training can help sentence embeddings learn the meaning of a sentence more directly.\nWe can achieve both points by using a pre-trained sentence encoder to produce our sentence embeddings. Several such encoders are available. We'll investigate InferSent and the Google Sentence Encoder."},{"metadata":{},"cell_type":"markdown","source":"## InferSent (errors)"},{"metadata":{},"cell_type":"markdown","source":"InferSent is a pre-trained encoder that produces sentence embeddings. More particularly, it is a BiLSTM with max pooling that was trained on the SNLI dataset, 570k English sentence pairs labelled with one of three categories: entailment, contradiction or neutral. InferSent was developed and trained by Facebook Research.\n\nLet's first download the resources we need."},{"metadata":{"trusted":true},"cell_type":"code","source":"!wget -nc https://raw.githubusercontent.com/facebookresearch/SentEval/master/examples/infersent.py\n!wget -nc https://dl.fbaipublicfiles.com/infersent/infersent1.pkl\n","execution_count":19,"outputs":[{"output_type":"stream","text":"--2020-05-19 14:15:40--  https://raw.githubusercontent.com/facebookresearch/SentEval/master/examples/infersent.py\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 2463 (2.4K) [text/plain]\nSaving to: ‘infersent.py’\n\ninfersent.py        100%[===================>]   2.41K  --.-KB/s    in 0s      \n\n2020-05-19 14:15:40 (40.1 MB/s) - ‘infersent.py’ saved [2463/2463]\n\n--2020-05-19 14:15:41--  https://dl.fbaipublicfiles.com/infersent/infersent1.pkl\nResolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 104.22.74.142, 2606:4700:10::6816:4b8e, ...\nConnecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 154010676 (147M) [application/octet-stream]\nSaving to: ‘infersent1.pkl’\n\ninfersent1.pkl      100%[===================>] 146.88M  72.1MB/s    in 2.0s    \n\n2020-05-19 14:15:43 (72.1 MB/s) - ‘infersent1.pkl’ saved [154010676/154010676]\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Then we load the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"# import torch\n\n# infersent = torch.load('infersent1.pkl', map_location=lambda storage, loc: storage)\n# infersent.use_cuda = False\n# torch.nn.Module.dump_patches = True\n# infersent.set_w2v_path(PATH_TO_GLOVE)","execution_count":20,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nFinally, we can run the benchmark by having InferSent encode the two sets of sentences and compute the cosine similarity between the corresponding sentences."},{"metadata":{"trusted":true},"cell_type":"code","source":"def run_inf_benchmark(sentences1, sentences2):\n    \n    raw_sentences1 = [sent1.raw for sent1 in sentences1]\n    raw_sentences2 = [sent2.raw for sent2 in sentences2]\n    \n    infersent.build_vocab(raw_sentences1 + raw_sentences2, tokenize=True)\n    embeddings1 = infersent.encode(raw_sentences1, tokenize=True)\n    embeddings2 = infersent.encode(raw_sentences2, tokenize=True)\n    \n    inf_sims = []\n    for (emb1, emb2) in zip(embeddings1, embeddings2): \n        sim = cosine_similarity(emb1.reshape(1, -1), emb2.reshape(1, -1))[0][0]\n        inf_sims.append(sim)\n\n    return inf_sims","execution_count":21,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Google Sentence Encoder"},{"metadata":{},"cell_type":"markdown","source":"The Google Sentence Encoder is Google's answer to Facebook's InferSent. It comes in two forms:\n\n- a Transformer model that takes the element-wise sum of the context-aware word representations produced by the encoding subgraph of a Transformer model.\n- a Deep Averaging Network (DAN) where input embeddings for words and bigrams are averaged together and passed through a feed-forward deep neural network.\n\nThe Transformer model tends to give better results, but at the time of writing, only the DAN-based encoder was available.\n\nIn contrast to InferSent, the Google Sentence Encoder was trained on a combination of unsupervised data (in a skip-thought-like task) and supervised data (the SNLI corpus).\n\nThe Google Sentence Encoder can be loaded from the Tensorflow Hub."},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf \nprint(tf.__version__)","execution_count":22,"outputs":[{"output_type":"stream","text":"2.1.0\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import logging","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow.compat.v1 as tf\n#To make tf 2.0 compatible with tf1.0 code, we disable the tf2.0 functionalities\ntf.disable_eager_execution()","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !pip install \"tensorflow_hub>=0.6.0\"","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow_hub as hub\n\ntf.logging.set_verbosity(tf.logging.ERROR)\n# embed = hub.Module(\"https://tfhub.dev/google/universal-sentence-encoder/4\")","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import tensorflow_hub as hub\n\n# logger = tf.get_logger()\n# logger.setLevel(logging.ERROR)\n# embed = hub.Module(\"https://tfhub.dev/google/universal-sentence-encoder/1\")","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\n\nembed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")","execution_count":28,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Like InferSent above, we'll have the it encode the two sets of sentences and return the similarities between the embeddings it produced."},{"metadata":{"trusted":true},"cell_type":"code","source":"def run_gse_benchmark(sentences1, sentences2):\n    sts_input1 = tf.placeholder(tf.string, shape=(None))\n    sts_input2 = tf.placeholder(tf.string, shape=(None))\n\n    sts_encode1 = tf.nn.l2_normalize(embed(sts_input1))\n    sts_encode2 = tf.nn.l2_normalize(embed(sts_input2))\n        \n    sim_scores = tf.reduce_sum(tf.multiply(sts_encode1, sts_encode2), axis=1)\n    \n    with tf.Session() as session:\n        session.run(tf.global_variables_initializer())\n        session.run(tf.tables_initializer())\n      \n        [gse_sims] = session.run(\n            [sim_scores],\n            feed_dict={\n                sts_input1: [sent1.raw for sent1 in sentences1],\n                sts_input2: [sent2.raw for sent2 in sentences2]\n            })\n    return gse_sims","execution_count":29,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Experiments"},{"metadata":{},"cell_type":"markdown","source":"Finally, it's time to run the actual experiments"},{"metadata":{"trusted":true},"cell_type":"code","source":"def run_experiment(df, benchmarks): \n    \n    sentences1 = [Sentence(s) for s in df['sent_1']]\n    sentences2 = [Sentence(s) for s in df['sent_2']]\n    \n    pearson_cors, spearman_cors = [], []\n    for label, method in benchmarks:\n        sims = method(sentences1, sentences2)\n        pearson_correlation = scipy.stats.pearsonr(sims, df['sim'])[0]\n        print(label, pearson_correlation)\n        pearson_cors.append(pearson_correlation)\n        spearman_correlation = scipy.stats.spearmanr(sims, df['sim'])[0]\n        spearman_cors.append(spearman_correlation)\n        \n    return pearson_cors, spearman_cors","execution_count":30,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import functools as ft\n\nbenchmarks = [(\"AVG-W2V\", ft.partial(run_avg_benchmark, model=word2vec, use_stoplist=False)),\n              (\"AVG-W2V-STOP\", ft.partial(run_avg_benchmark, model=word2vec, use_stoplist=True)),\n              (\"AVG-W2V-TFIDF\", ft.partial(run_avg_benchmark, model=word2vec, use_stoplist=False, doc_freqs=doc_frequencies)),\n              (\"AVG-W2V-TFIDF-STOP\", ft.partial(run_avg_benchmark, model=word2vec, use_stoplist=True, doc_freqs=doc_frequencies)),\n#               (\"AVG-GLOVE\", ft.partial(run_avg_benchmark, model=glove, use_stoplist=False)),\n#               (\"AVG-GLOVE-STOP\", ft.partial(run_avg_benchmark, model=glove, use_stoplist=True)),\n#               (\"AVG-GLOVE-TFIDF\", ft.partial(run_avg_benchmark, model=glove, use_stoplist=False, doc_freqs=doc_frequencies)),\n#               (\"AVG-GLOVE-TFIDF-STOP\", ft.partial(run_avg_benchmark, model=glove, use_stoplist=True, doc_freqs=doc_frequencies)),\n              (\"WMD-W2V\", ft.partial(run_wmd_benchmark, model=word2vec, use_stoplist=False)), \n              (\"WMD-W2V-STOP\", ft.partial(run_wmd_benchmark, model=word2vec, use_stoplist=True)), \n#               (\"WMD-GLOVE\", ft.partial(run_wmd_benchmark, model=glove, use_stoplist=False)), \n#               (\"WMD-GLOVE-STOP\", ft.partial(run_wmd_benchmark, model=glove, use_stoplist=True)), \n              (\"SIF-W2V\", ft.partial(run_sif_benchmark, freqs=frequencies, model=word2vec, use_stoplist=False)),\n#               (\"SIF-GLOVE\", ft.partial(run_sif_benchmark, freqs=frequencies, model=glove, use_stoplist=False)), \n#               (\"INF\", run_inf_benchmark),\n              (\"GSE\", run_gse_benchmark)\n             ]","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow.compat.v1 as tf\n\ntf.disable_v2_behavior()","execution_count":32,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pearson_results, spearman_results = {}, {}\npearson_results[\"SICK-DEV\"], spearman_results[\"SICK-DEV\"] = run_experiment(micro_df, benchmarks)\nprint(\" \")\npearson_results[\"SICK-TEST\"], spearman_results[\"SICK-TEST\"] = run_experiment(micro_df, benchmarks)\nprint(\" \")\npearson_results[\"STS-DEV\"], spearman_results[\"STS-DEV\"] = run_experiment(micro_df, benchmarks)\nprint(\" \")\npearson_results[\"STS-TEST\"], spearman_results[\"STS-TEST\"] = run_experiment(micro_df, benchmarks)","execution_count":33,"outputs":[{"output_type":"stream","text":"AVG-W2V 0.749077063813995\nAVG-W2V-STOP 0.7840124772980328\nAVG-W2V-TFIDF 0.4836831148682583\nAVG-W2V-TFIDF-STOP 0.7686857407993766\nWMD-W2V 0.5387174735752565\nWMD-W2V-STOP 0.7026423920226675\nSIF-W2V 0.8214520679730857\nGSE 0.861044543751366\n \nAVG-W2V 0.749077063813995\nAVG-W2V-STOP 0.7840124772980328\nAVG-W2V-TFIDF 0.4836831148682583\nAVG-W2V-TFIDF-STOP 0.7686857407993766\nWMD-W2V 0.5387174735752565\nWMD-W2V-STOP 0.7026423920226675\nSIF-W2V 0.8214520679730857\nGSE 0.861044543751366\n \nAVG-W2V 0.749077063813995\nAVG-W2V-STOP 0.7840124772980328\nAVG-W2V-TFIDF 0.4836831148682583\nAVG-W2V-TFIDF-STOP 0.7686857407993766\nWMD-W2V 0.5387174735752565\nWMD-W2V-STOP 0.7026423920226675\nSIF-W2V 0.8214520679730857\nGSE 0.861044543751366\n \nAVG-W2V 0.749077063813995\nAVG-W2V-STOP 0.7840124772980328\nAVG-W2V-TFIDF 0.4836831148682583\nAVG-W2V-TFIDF-STOP 0.7686857407993766\nWMD-W2V 0.5387174735752565\nWMD-W2V-STOP 0.7026423920226675\nSIF-W2V 0.8214520679730857\nGSE 0.861044543751366\n","name":"stdout"}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}